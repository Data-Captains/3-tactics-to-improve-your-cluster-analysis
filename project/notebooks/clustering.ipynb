{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Tactics to Improve your Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Mall Customers dataset, which is available for download\n",
    "[from Kaggle](https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python)\n",
    "for example.\n",
    "\n",
    "The dataset contains information about 200 mall customers. For each of the 200\n",
    "mall customers, the dataset includes\n",
    "- a `CustomerID`\n",
    "- the customer's `Gender`\n",
    "- the customer's `Age`\n",
    "- the customer's `Annual Income` (in thousands of USD)\n",
    "- a `Spending Score` (between 1 and 100) assigned by the mall to each customer\n",
    "  based on the customer's spending habits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import (\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/mall_customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going to use the `CustomerID` for the purpose of clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"CustomerID\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple, we will also ignore the only categorical variable in the\n",
    "dataset i.e., the customer's `Gender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"Gender\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standardize the variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data = StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data.var(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed for sklearn estimators\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusterer_score(clusterer, data, score_function):\n",
    "    \"\"\"Evaluates a clusterer with respect to a score.\"\"\"\n",
    "    labels = clusterer.labels_\n",
    "    return score_function(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cluster_analysis(\n",
    "    clusterer,\n",
    "    parameter_name,\n",
    "    parameter_values,\n",
    "    data,\n",
    "    score_function,\n",
    "    larger_is_better=True,\n",
    "):\n",
    "    \"\"\"Analyzes the performance of a clusterer with respect to a score and\n",
    "    as a function of its (main) tuning parameter.\"\"\"\n",
    "    scores = []\n",
    "    for parameter_value in parameter_values:\n",
    "        clusterer.set_params(**{parameter_name: parameter_value})\n",
    "        clusterer = clusterer.fit(data)\n",
    "        score = get_clusterer_score(clusterer, data, score_function)\n",
    "        scores.append(score)\n",
    "    return {\n",
    "        \"parameter_name\": parameter_name,\n",
    "        \"parameter_values\": parameter_values,\n",
    "        \"data\": data,\n",
    "        \"score_function\": score_function,\n",
    "        \"scores\": scores,\n",
    "        \"best_parameter_value\": parameter_values[np.argmax(scores)]\n",
    "        if larger_is_better\n",
    "        else parameter_values[np.argmin(scores)],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_analysis(clusterer_analysis, path=None):\n",
    "    parameter_name = clusterer_analysis[\"parameter_name\"]\n",
    "    parameter_values = clusterer_analysis[\"parameter_values\"]\n",
    "    scores = clusterer_analysis[\"scores\"]\n",
    "    score_function_name = clusterer_analysis[\"score_function\"].__qualname__\n",
    "\n",
    "    plt.plot(parameter_values, scores)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel(parameter_name)\n",
    "    ax.set_ylabel(score_function_name)\n",
    "    ax.set_xticks(parameter_values)\n",
    "    ax.set_xticklabels(parameter_values)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticklabels([])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if path:\n",
    "        plt.savefig(path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering(clusterer, data, path=None):\n",
    "    data_copy = data.copy()\n",
    "    data_copy[\"labels\"] = clusterer.labels_\n",
    "\n",
    "    n_colors = clusterer.labels_.max() - clusterer.labels_.min() + 1\n",
    "    sns.pairplot(data_copy, hue=\"labels\", palette=sns.color_palette(\"husl\", n_colors))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if path:\n",
    "        plt.savefig(path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_tabulate_clusterers(clusterer0, clusterer1, clusterer0_name, clusterer1_name):\n",
    "    \"\"\"Creates a cross-tabulation of the clusters found by two clusterers\n",
    "    that allows to evaluate their agreement.\n",
    "    \"\"\"\n",
    "    if clusterer1.labels_.max() >= clusterer0.labels_.max():\n",
    "        clusterer0, clusterer1 = clusterer1, clusterer0\n",
    "        clusterer0_name, clusterer1_name = clusterer1_name, clusterer0_name\n",
    "\n",
    "    cross_tab = pd.crosstab(\n",
    "        clusterer0.labels_,\n",
    "        clusterer1.labels_,\n",
    "        rownames=[clusterer0_name],\n",
    "        colnames=[clusterer1_name],\n",
    "    )\n",
    "\n",
    "    optimal_column_permutation = linear_sum_assignment(-cross_tab)[1]\n",
    "    return cross_tab.loc[:, optimal_column_permutation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(data)\n",
    "plt.savefig(\"pairplot.jpeg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=RANDOM_STATE).fit(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering(kmeans, data, path=\"kmeans-clustering.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tactic 1: Algorithm Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use k-means clustering with the Silhouette Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_analysis_silhouette = make_cluster_analysis(\n",
    "    clusterer=KMeans(random_state=RANDOM_STATE),\n",
    "    parameter_name=\"n_clusters\",\n",
    "    parameter_values=np.arange(2, 16),\n",
    "    data=standardized_data,\n",
    "    score_function=silhouette_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analysis(kmeans_analysis_silhouette, path=\"kmeans-silhouette-tuning.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_analysis_silhouette[\"best_parameter_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Silhouette score suggests 6 (or 10?) clusters. Accordingly, we fit a k-means\n",
    "model with 6 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_silhouette = KMeans(\n",
    "    n_clusters=kmeans_analysis_silhouette[\"best_parameter_value\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ").fit(standardized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering(kmeans_silhouette, data, path=\"kmeans-silhouette-clustering.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some statistics for these clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data = data.copy()\n",
    "clustered_data[\"label\"] = kmeans_silhouette.labels_\n",
    "clustered_data.groupby(\"label\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about choosing the second-best parameter value i.e., `n_clusters = 10`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_silhouette10 = KMeans(\n",
    "    n_clusters=10,\n",
    "    random_state=RANDOM_STATE,\n",
    ").fit(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering(kmeans_silhouette10, data, path=\"kmeans-silhouette10-clustering.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tabulate_clusterers(\n",
    "    kmeans_silhouette, kmeans_silhouette10, \"kmeans_6\", \"kmeans_10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that with `n_clusters = 10`, some of the existing clusters are further\n",
    "broken down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tactic 2: Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we used the Calinski-Harabasz score instead of the Silhouette score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_analysis_ch = make_cluster_analysis(\n",
    "    clusterer=KMeans(random_state=RANDOM_STATE),\n",
    "    parameter_name=\"n_clusters\",\n",
    "    parameter_values=np.arange(2, 16),\n",
    "    data=standardized_data,\n",
    "    score_function=calinski_harabasz_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analysis(kmeans_analysis_ch, path=\"kmeans-ch-tuning.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_analysis_ch[\"best_parameter_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Calinski-Harabasz score suggests 11 clusters, although 6 is still a highly\n",
    "scored parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ch = KMeans(\n",
    "    n_clusters=kmeans_analysis_ch[\"best_parameter_value\"], random_state=RANDOM_STATE\n",
    ").fit(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tabulate_clusterers(\n",
    "    kmeans_silhouette, kmeans_ch, \"kmeans_silhouette\", \"kmeans_ch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model tuned using the Calinski-Harabasz score provides a\n",
    "more fine-grained clustering than the model tuned using the Silhouette\n",
    "score.\n",
    "\n",
    "Some clusters found by the latter are further split by the former (e.g.,\n",
    "cluster 4 of the model tuned using the Silhouette score is split into two\n",
    "clusters - cluster 5 and 7 - by the model tuned using the Calinski-Harabasz\n",
    "score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the Davies-Bouldin score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_analysis_db = make_cluster_analysis(\n",
    "    clusterer=KMeans(random_state=RANDOM_STATE),\n",
    "    parameter_name=\"n_clusters\",\n",
    "    parameter_values=np.arange(2, 16),\n",
    "    data=standardized_data,\n",
    "    score_function=davies_bouldin_score,\n",
    "    larger_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analysis(kmeans_analysis_db, path=\"kmeans-db-tuning.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_analysis_db[\"best_parameter_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Davies-Bouldin score suggests again 6 clusters, though 10 is again scored\n",
    "very favorably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_db = KMeans(\n",
    "    n_clusters=kmeans_analysis_db[\"best_parameter_value\"], random_state=RANDOM_STATE\n",
    ").fit(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tabulate_clusterers(\n",
    "    kmeans_silhouette, kmeans_db, \"kmeans_silhouette\", \"kmeans_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters found by the model tuned using the Davies-Bouldin score are\n",
    "exactly the same as the ones found by the model tuned using the Silhouette\n",
    "score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tactic 3: Consensus Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we used another clustering algorithm such as agglomerative clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_analysis_silhouette = make_cluster_analysis(\n",
    "    clusterer=AgglomerativeClustering(),\n",
    "    parameter_name=\"n_clusters\",\n",
    "    parameter_values=np.arange(2, 16),\n",
    "    data=standardized_data,\n",
    "    score_function=silhouette_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analysis(\n",
    "    agglomerative_analysis_silhouette, path=\"agglomerative-silhouette-tuning.jpeg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_analysis_silhouette[\"best_parameter_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Calinski-Harabasz score, Agglomerative Clustering finds 6 clusters.\n",
    "\n",
    "Are these the same as the ones found by k-means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_silhouette = AgglomerativeClustering(\n",
    "    n_clusters=agglomerative_analysis_silhouette[\"best_parameter_value\"]\n",
    ").fit(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tabulate_clusterers(\n",
    "    kmeans_silhouette,\n",
    "    agglomerative_silhouette,\n",
    "    \"kmeans_silhouette\",\n",
    "    \"agglomerative_silhouette\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we tuned Agglomerative Clustering using other score functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_analysis_ch = make_cluster_analysis(\n",
    "    clusterer=AgglomerativeClustering(),\n",
    "    parameter_name=\"n_clusters\",\n",
    "    parameter_values=np.arange(2, 16),\n",
    "    data=standardized_data,\n",
    "    score_function=calinski_harabasz_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analysis(agglomerative_analysis_ch, path=\"agglomerative-ch-tuning.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_ch = AgglomerativeClustering(\n",
    "    n_clusters=agglomerative_analysis_ch[\"best_parameter_value\"]\n",
    ").fit(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tabulate_clusterers(\n",
    "    kmeans_silhouette, agglomerative_ch, \"kmeans_silhouette\", \"agglomerative_ch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_analysis_db = make_cluster_analysis(\n",
    "    clusterer=AgglomerativeClustering(),\n",
    "    parameter_name=\"n_clusters\",\n",
    "    parameter_values=np.arange(2, 16),\n",
    "    data=standardized_data,\n",
    "    score_function=davies_bouldin_score,\n",
    "    larger_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analysis(agglomerative_analysis_db, path=\"agglomerative-db-tuning.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_db = AgglomerativeClustering(\n",
    "    n_clusters=agglomerative_analysis_db[\"best_parameter_value\"]\n",
    ").fit(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tabulate_clusterers(\n",
    "    kmeans_silhouette, agglomerative_db, \"kmeans_silhouette\", \"agglomerative_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, it seems there is a large amount of agreement between the\n",
    "results generated by these two algorithms.\n",
    "\n",
    "It appears that there may in fact be 6 clusters in this dataset, with\n",
    "potentially additional sub-clusters of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to be careful, however.\n",
    "\n",
    "In general, scoring functions do not automatically prevent us from making\n",
    "foolish choices.\n",
    "\n",
    "For example, here is what the Calinski-Harabasz score looks like for very large\n",
    "values of `n_clusters` in k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ch_large_n_clusters = make_cluster_analysis(\n",
    "    clusterer=KMeans(random_state=RANDOM_STATE),\n",
    "    parameter_name=\"n_clusters\",\n",
    "    parameter_values=np.array(\n",
    "        [2, 6, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192]\n",
    "    ),\n",
    "    data=standardized_data,\n",
    "    score_function=calinski_harabasz_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analysis(kmeans_ch_large_n_clusters, path=\"kmeans-ch-tuning-large-n-clusters.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d398d5d8e5234f411a3ed210b36ae07c86e6a21a535933210afe93a83bf63291"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('3-strategies-to-improve-cluster-analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
